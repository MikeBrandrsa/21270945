---
title: "Question 3: A ALSI Concentration analysis."
author: "Michael Charles Brand"
date: "November 2021"
# date: "`r Sys.Date()`"
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
output:
  pagedown::html_paged:
    # template: wp_paged.html
    # css: ['wp.css', 'wp-fonts.css', 'wp-page.css']
    css: ["Template/default-fonts-Texevier.css", "Template/default-page-Texevier.css", "Template/default-Texevier.css"]
    csl: Template/harvard-stellenbosch-university.csl # referencing format used.
    template: ["Template/paged-Texevier.html"]

    toc: true
    # change to true for a self-contained document, but it'll be a litte slower for Pandoc to render
    self_contained: TRUE
abstract: |
   In this question the concentration and commonality of returns in the top 40 indices is investigated. This begins with a principal component analysis understanding how concentrated the primary factors are in influencing the entire index. Whereafter a CAPM style correlation to a risk free rate is analysed and inferences are made about diversification, Potentially during the pandemic as well. 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
pacman::p_load(modelsummary, gt, knitr, kableExtra, tidyverse)
```

\newpage

# Question 3: Volatility Comparison
Index investing is often seen as a safe a benchmark to sector specific portfolios in conventional financial theory, For this slightly outdated reason as well as the key drivers of indices giving important information about the vulnerability to systemic risk, Understanding the concentration and commonality of returns within an index Provides key insights. Often times indices are used as a low beta benchmarks or are used as controls in econometric regressions. Here I unpack the returns from the J200 return series specifically as follows  

get return series for just j200
```{r, include=FALSE, eval=FALSE}
#pacman::p_load("tidyverse", "devtools", "FactoMineR", "factoextra", 
   # "broom", "rmsfuns")
#T40 <- read_rds("data/T40.rds")
#Q2ALSIRTN <- T40  %>% arrange(date) %>% select(date, Tickers, Return, J200) %>% drop_na()
#colSums(is.na(Q3ALSIRTN))
#WghtALSIRTN <- Q3ALSIRTN %>% mutate(effectivereturn = Return*J200) %>% 
 #   group_by(date) %>% summarise(portfolio_return = sum(effectivereturn)) %>% ungroup()
 # this is for Q2 

```

```{r, echo=FALSE}
pacman::p_load("tidyverse", "devtools", "FactoMineR", "factoextra", 
    "broom", "rmsfuns")
T40 <- read_rds("data/T40.rds")
Q3ALSIRTN <- T40  %>% arrange(date) %>% select(date, Tickers, Return, J200) %>% drop_na() %>% select(date, Tickers, Return) %>% mutate(Return = ifelse(Return > 0.25, 0.25, 
    ifelse(Return < -0.25, -0.25, Return)))
colSums(is.na(Q3ALSIRTN))
```
In this analysis specifically it is the over-arching relations between constituents, and of movements of the all the in general, that are desirable. For this reason it is acceptable to winsorise the data as observed above to obtain cleaner estimates. 

As a sanity check I also take note that no columns are left out.My process of thinking here was to arrange the data in terms of the J200 series with non-weighted J 400 constituents, whereafter the J400 SWIX constituents were removed. 
```{r, warning=FALSE}
Q3plot1 <- Q3ALSIRTN %>% ggplot() + geom_line(aes(date, Return, color=Tickers, alpha =0.9)) +
                                                   labs(x = "date", y = "Returns", title = "top40 ALSI Returns", subtitle = "", caption = "Note:\nNico Katzke's data used") + theme(legend.position = "none")
Q3plot1
```
Before a principal component analysis is conducted it is worthwhile ensuring that the series has been standardised around zero, As was insured above. Whilst the values were not in the N.a format that can be observed in the graph above that some values were not desirable, For a successful correlation matrix to be run and R I need to fill any values that might cause problems, 
```{r, echo = T, results = 'hide'}

Q3centered <- Q3ALSIRTN %>% group_by(Tickers) %>% mutate(Return = Return - mean(Return)) %>% ungroup() %>% spread(Tickers, Return)


set.seed(1234)
        NAll <- nrow(Q3centered %>% gather(Return, Returns, -date))

Q3centered <- bind_cols(
          Q3centered %>% gather(Tickers, Return, -date),
          Q3centered %>% gather(Tickers, Return, -date) %>%
            mutate(Dens = list(density(Return, na.rm=T))) %>%
            summarise(Random_Draws = list(sample(Dens[[1]]$x, NAll, replace = TRUE, prob=.$Dens[[1]]$y))) %>% 
            unnest(Random_Draws)) %>% mutate(Return = coalesce(Return, Random_Draws)) %>% select(-Random_Draws) %>% spread(Tickers, Return)
return(Q3centered)
any(is.na(Q3centered))
```
The above code is a direct way in which I imputed the returns of individual stocks taken from the distribution of all of the constituents of the return series. As this is a PCA directed approach it made sense to use a collective distribution so that the overall influence of orthogonal shocks could still be accurately analised.
\newpage
Below I convert this newlyformed matrix type data frame into a covariance matrix after the date is removed.
```{r, echo=FALSE}
Q3centemax <- Q3centered %>% select(-date)
Q3covmat <- cov(Q3centemax)  
```

```{r, echo=FALSE}
# eigenvectors:
evec <- eigen(Q3covmat, symmetric = TRUE)$vector
# eigenvalues:
eval <- eigen(Q3covmat, symmetric = TRUE)$values

lambda = diag(t(evec) %*% Q3covmat %*% evec)
# Which should be equal to eval:
all.equal(lambda, eval)
prcomp(Q3covmat)
prop = eval/sum(eval)
```

```{r}
print(prop)
```
Here the proportions of the effects of the principal components are briefly reviewed although I will present them more conveniently below. 
```{r}
prop <- tibble(Loadings = prop) %>% mutate(PC = paste0("PC_", 
    row_number()))

prop[, "PC"][[1]] <- factor(prop[, "PC"][[1]], levels = prop$PC)
Prop2 <- prop %>% slice_head(n=10)
g <- Prop2 %>% 
ggplot() + geom_bar(aes(PC, Loadings), stat = "identity", fill = "steelblue") + 
    
fmxdat::theme_fmx(axis.size.title = fmxdat::ggpts(38), axis.size = fmxdat::ggpts(35), 
    title.size = fmxdat::ggpts(42), CustomCaption = T) + 
scale_y_continuous(breaks = scales::pretty_breaks(10), labels = scales::percent_format(accuracy = 1)) + 
labs(x = "Principal Components", y = "Loadings", title = "Eigenvalue proportions", 
    caption = "Source: Fmxdat Package")
g
```
Before interpreting these values I make mention of the fact that I subsets the principal component to only show the first 10 in the graph. As is typical of the nature of these eigenvalue proportions in this PCA framework, After the fourth principal component, each additional component only explains between 1.5% to 2% of the variation within the top40. In re-visiting the first principal component I note that 12% of the variation within the top 40 is explained by a single component and although we might not know with certainty what this factor is, it has been calculated linearly as observed. Normally in an analysis of the style the next step would be to represent the eigenvector proportions or loading victors graphically, In this case the size of the components makes this a numeric exercise is a poster visual one. For the sake of completeness It is worth mentioning that in this Eigenvector analysis the distribution of the effects of the Different principal components can be observed for the manner in which they load into different variables. 

```{r, include=FALSE}
#pcaseries <- Q3ALSIRTN %>% spread(Tickers, Return) %>% select(-date)
#demean = scale(pcaseries, center = TRUE, scale = TRUE)


#Q3ALSIRTN

#sigma <- cov(demean )

#evec <- eigen(sigma, symmetric = TRUE)$vector  #eigen vectors
#eval <- eigen(sigma, symmetric = TRUE)$values  #eigen values

# or done automagically (using standard covariance matrix
# warts and all):
#pcrun <- prcomp(demean, center = T, scale. = T)
#ev <- pcrun$rotation

#e_min1 <- solve(ev)  # Invert eigenvector as in equation above)
#R_PCA <- e_min1 %*% t(pcaseries)  # Note: pcaseries, not demean.

#PC_Series <- t(R_PCA) %>% tibble::as_tibble()

#PC_Series <- PC_Series %>% mutate(date = unique(Spots$date)) %>% 
    #gather(Type, Val, -date)

#---- Let's look at these series:

# Returns:
#PC_Series %>% filter(Type %in% paste0("PC", 1:5)) %>% ggplot() + 
    #geom_line(aes(date, Val, color = Type))



```
The direction I take from here is that as instead of loading supplementary variables onto the PCA analysis, I instead investigate correlations From a CAPM portfolio-theory perspective. For a slightly different perspective on the concentration of this index. Here the SA 3 Month bond is used as a proxy for the risk free rate. Below I convert it to a timeseries table and apply a CAPM, Three month  rolling correlation. 
```{r, warning = FALSE}
library(PerformanceAnalytics)
library(tbl2xts)
rf <-read_rds("data/SA_Bonds.rds") %>% 
    select(date, SA_3M) %>%  gather(Bond, Yield, -date) %>%
    arrange(date)
rfxts <- tbl_xts(rf)

xtsQ3ALSIRTN <- tbl_xts(Q3ALSIRTN)
chart.RollingCorrelation(Ra = xtsQ3ALSIRTN , Rb=rfxts, width = 62, xaxis = TRUE,
  legend.loc = NULL, colorset = (1:12), fill = NA)  

```
This rolling correlation is promising from a diversification perspective as it is clearly observable that it revolves around a zero mean consistently meaning that periods of high positive and high negative correlation persistence is unlikely. Taking into account that the highest factor influencing the first principal component was only 12% and drop down to below 5% for the second principal component it is substantiated that there are low levels of commonality of returns within the top 40 index. Before moving on to the following questions it is worth noting that having a portion of a portfolio in bonds during the pandemic would have provided good diversification against that of emerging markets and specifically South African equity as can be observed above.This does of course need to be analysed with in an optimisation routine of course.
